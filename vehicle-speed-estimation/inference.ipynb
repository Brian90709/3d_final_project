{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can find a pretrained model at model/b3.pth\n",
    "MODEL_F = 'model/b3_128.pth'\n",
    "# directory with the numpy optical flow images you want to use for inference\n",
    "OF_NPY_DIR = '../opical-flow-estimation-with-RAFT/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if cuda is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 0     # what version of efficientnet did you use\n",
    "IN_C = 2  # number of input channels\n",
    "NUM_C = 1 # number of classes to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained(f'efficientnet-b{V}', in_channels=IN_C, num_classes=NUM_C)\n",
    "state = torch.load(MODEL_F)\n",
    "model.load_state_dict(state)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(of_f):\n",
    "    of = np.load(of_f)\n",
    "    i = torch.from_numpy(of).to(device)\n",
    "    pred = model(i)\n",
    "    del i\n",
    "    torch.cuda.empty_cache()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../opical-flow-estimation-with-RAFT/output/0.npy: 23.95\n",
      "../opical-flow-estimation-with-RAFT/output/1.npy: 24.04\n",
      "../opical-flow-estimation-with-RAFT/output/2.npy: 24.21\n",
      "../opical-flow-estimation-with-RAFT/output/3.npy: 23.81\n",
      "../opical-flow-estimation-with-RAFT/output/4.npy: 24.61\n",
      "../opical-flow-estimation-with-RAFT/output/5.npy: 25.04\n",
      "../opical-flow-estimation-with-RAFT/output/6.npy: 23.55\n",
      "../opical-flow-estimation-with-RAFT/output/7.npy: 24.28\n",
      "../opical-flow-estimation-with-RAFT/output/8.npy: 23.7\n",
      "../opical-flow-estimation-with-RAFT/output/9.npy: 24.73\n",
      "../opical-flow-estimation-with-RAFT/output/10.npy: 24.72\n",
      "../opical-flow-estimation-with-RAFT/output/11.npy: 25.27\n",
      "../opical-flow-estimation-with-RAFT/output/12.npy: 22.99\n",
      "../opical-flow-estimation-with-RAFT/output/13.npy: 24.89\n",
      "../opical-flow-estimation-with-RAFT/output/14.npy: 24.5\n",
      "../opical-flow-estimation-with-RAFT/output/15.npy: 24.37\n",
      "../opical-flow-estimation-with-RAFT/output/16.npy: 24.17\n",
      "../opical-flow-estimation-with-RAFT/output/17.npy: 24.81\n",
      "../opical-flow-estimation-with-RAFT/output/18.npy: 24.94\n",
      "../opical-flow-estimation-with-RAFT/output/19.npy: 24.74\n",
      "../opical-flow-estimation-with-RAFT/output/20.npy: 25.17\n",
      "../opical-flow-estimation-with-RAFT/output/21.npy: 24.42\n",
      "../opical-flow-estimation-with-RAFT/output/22.npy: 24.82\n",
      "../opical-flow-estimation-with-RAFT/output/23.npy: 24.57\n",
      "../opical-flow-estimation-with-RAFT/output/24.npy: 24.73\n",
      "../opical-flow-estimation-with-RAFT/output/25.npy: 24.07\n",
      "../opical-flow-estimation-with-RAFT/output/26.npy: 24.75\n",
      "../opical-flow-estimation-with-RAFT/output/27.npy: 25.28\n",
      "../opical-flow-estimation-with-RAFT/output/28.npy: 25.39\n",
      "../opical-flow-estimation-with-RAFT/output/29.npy: 24.15\n",
      "../opical-flow-estimation-with-RAFT/output/30.npy: 24.05\n",
      "../opical-flow-estimation-with-RAFT/output/31.npy: 23.9\n",
      "../opical-flow-estimation-with-RAFT/output/32.npy: 24.58\n",
      "../opical-flow-estimation-with-RAFT/output/33.npy: 25.11\n",
      "../opical-flow-estimation-with-RAFT/output/34.npy: 25.17\n",
      "../opical-flow-estimation-with-RAFT/output/35.npy: 24.57\n",
      "../opical-flow-estimation-with-RAFT/output/36.npy: 23.88\n",
      "../opical-flow-estimation-with-RAFT/output/37.npy: 25.14\n",
      "../opical-flow-estimation-with-RAFT/output/38.npy: 24.64\n",
      "../opical-flow-estimation-with-RAFT/output/39.npy: 24.54\n"
     ]
    }
   ],
   "source": [
    "# loop over all files in directory and predict\n",
    "# for f in Path(OF_NPY_DIR).glob('*.npy'):\n",
    "#     y_hat = inference(f).item()\n",
    "#     print(f'{f.name}: {round(y_hat, 2)}')\n",
    "for i in range(40):\n",
    "    f = OF_NPY_DIR + '/' + str(i) + '.npy'\n",
    "    y_hat = inference(f).item()\n",
    "    print(f'{f}: {round(y_hat, 2)}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
