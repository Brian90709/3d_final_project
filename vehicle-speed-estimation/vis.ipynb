{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can find a pretrained model at model/b3.pth\n",
    "MODEL_F = 'model/b2/best.pth'\n",
    "# directory with the numpy optical flow images you want to use for inference\n",
    "OF_NPY_DIR = '../opical-flow-estimation-with-RAFT/output'\n",
    "# OF_NPY_DIR = 'npy'\n",
    "Video_dir = 'images/train.mp4'\n",
    "GT_dir = 'train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if cuda is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 2     # what version of efficientnet did you use\n",
    "IN_C = 2  # number of input channels\n",
    "NUM_C = 1 # number of classes to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained(f'efficientnet-b{V}', in_channels=IN_C, num_classes=NUM_C)\n",
    "state = torch.load(MODEL_F)\n",
    "model.load_state_dict(state)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(of_f):\n",
    "    of = np.load(of_f)\n",
    "    i = torch.from_numpy(of).to(device)\n",
    "    pred = model(i)\n",
    "    del i\n",
    "    torch.cuda.empty_cache()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "f = open(GT_dir)\n",
    "GT = f.readlines()\n",
    "\n",
    "# Input\n",
    "vidcap = cv2.VideoCapture(Video_dir)\n",
    "success, frame = vidcap.read()\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, 20.0, (640,  480))\n",
    "out.write(frame)\n",
    "\n",
    "count = 0\n",
    "while success and count < 3600:\n",
    "    success, frame = vidcap.read()\n",
    "    f = OF_NPY_DIR + '/' + str(count) + '.npy'\n",
    "    if not os.path.isfile(f):\n",
    "        break\n",
    "    \n",
    "    if count >= 3000:\n",
    "        y_hat = inference(f).item()\n",
    "        pred = 'Pred: ' + str(round(y_hat, 2)) + 'mph'\n",
    "        gt = 'GT: ' + GT[count].split('.')[0] + '.' + GT[count].split('.')[1][:2] + 'mph'\n",
    "        diff = 'diff: ' + str(round(float(GT[count]) - y_hat, 2))\n",
    "        cv2.putText(frame, pred, (0, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, gt, (0, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, diff, (0, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "        out.write(frame)\n",
    "    count += 1\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.isfile('../opical-flow-estimation-with-RAFT/output/20398.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 320, 640)\n"
     ]
    }
   ],
   "source": [
    "of = np.load('../opical-flow-estimation-with-RAFT/output1/20398.npy')\n",
    "print(of.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.1273618  -0.13245387 -0.13652012 ...  2.4380157   2.4340835\n",
      "     2.4277139 ]\n",
      "   [-0.12973347 -0.13490614 -0.1383553  ...  2.4388032   2.4351673\n",
      "     2.4324136 ]\n",
      "   [-0.13076115 -0.13579664 -0.13839947 ...  2.4393146   2.436145\n",
      "     2.4348946 ]\n",
      "   ...\n",
      "   [-2.3053896  -2.3054514  -2.3026412  ...  1.4114022   1.6261985\n",
      "     1.8427379 ]\n",
      "   [-2.2984984  -2.3005958  -2.297174   ...  1.2677288   1.3977143\n",
      "     1.5467987 ]\n",
      "   [-2.2910452  -2.2942796  -2.292251   ...  1.1680415   1.2705206\n",
      "     1.3680716 ]]\n",
      "\n",
      "  [[-0.0727099  -0.06925774 -0.06701323 ... -1.0413845  -1.0378234\n",
      "    -1.036514  ]\n",
      "   [-0.07134464 -0.06826704 -0.06633865 ... -1.0406389  -1.0356193\n",
      "    -1.0314789 ]\n",
      "   [-0.07090738 -0.06831974 -0.06688016 ... -1.0368154  -1.0328224\n",
      "    -1.0278083 ]\n",
      "   ...\n",
      "   [ 0.66085434  0.6659317   0.6702154  ...  0.4179353   0.5327205\n",
      "     0.6494239 ]\n",
      "   [ 0.6722083   0.6745251   0.67922896 ...  0.33245742  0.40263432\n",
      "     0.48313284]\n",
      "   [ 0.6828357   0.6826558   0.6857843  ...  0.26856136  0.3237476\n",
      "     0.37784538]]]]\n"
     ]
    }
   ],
   "source": [
    "print(of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
